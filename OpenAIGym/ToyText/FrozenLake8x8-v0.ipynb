{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "from utils import file_exists, evaluate_model, eval_env_random_actions\n",
    "from icecream import ic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from plotnine import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n"
     ]
    }
   ],
   "source": [
    "# frozen-lake-ex1.py\n",
    "import gym # loading the Gym library\n",
    " \n",
    "# env = gym.make(\"FrozenLake-v1\")\n",
    "env = gym.make(\"FrozenLake8x8-v1\")\n",
    "\n",
    "env.reset()                    \n",
    "env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(4)\n",
      "Discrete(64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(env.action_space)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "random_action = env.action_space.sample() # Do random actions\n",
    "print(random_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Right)\n",
      "SFFFFFFF\n",
      "FF\u001b[41mF\u001b[0mFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n"
     ]
    }
   ],
   "source": [
    "# state, reward, done, info = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'FrozenLake-v1'\n",
    "\n",
    "# # Create folder to save models\n",
    "# directory_path = 'models'\n",
    "# Path(directory_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# num_steps = 100_000\n",
    "# model_file_name = Path(directory_path, env_name+'_'+str(num_steps))\n",
    "\n",
    "env = gym.make(env_name,\n",
    "#  is_slippery=False,map_name=\"8x8\"\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| random_action: 0\n",
      "ic| state: 4\n",
      "    reward: 0.0\n",
      "    done: False\n",
      "    info: {'prob': 0.3333333333333333}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "random_action = env.action_space.sample() # Do random actions # LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3\n",
    "\n",
    "state = env.reset()\n",
    "state, reward, done, info = env.step(random_action)\n",
    "ic(random_action)\n",
    "ic(state, reward, done, info) \n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing random actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "# eval_env_random_actions(env, episodes=2)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/repositories/AlgoRL/.valgorl/lib/python3.8/site-packages/gym/envs/toy_text/frozen_lake.py:169\u001b[0m, in \u001b[0;36mFrozenLakeEnv.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/mattiacinelli/repositories/AlgoRL/.valgorl/lib/python3.8/site-packages/gym/envs/toy_text/frozen_lake.py?line=167'>168</a>\u001b[0m \u001b[39mwith\u001b[39;00m closing(outfile):\n\u001b[0;32m--> <a href='file:///Users/mattiacinelli/repositories/AlgoRL/.valgorl/lib/python3.8/site-packages/gym/envs/toy_text/frozen_lake.py?line=168'>169</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m outfile\u001b[39m.\u001b[39;49mgetvalue()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OutStream' object has no attribute 'getvalue'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mattiacinelli/repositories/AlgoRL/algorl/gym_examples/classics/FrozenLake8x8-v0.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mattiacinelli/repositories/AlgoRL/algorl/gym_examples/classics/FrozenLake8x8-v0.ipynb#ch0000029?line=0'>1</a>\u001b[0m env\u001b[39m.\u001b[39;49mrender(mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrgb_array\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/repositories/AlgoRL/.valgorl/lib/python3.8/site-packages/gym/core.py:254\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/mattiacinelli/repositories/AlgoRL/.valgorl/lib/python3.8/site-packages/gym/core.py?line=252'>253</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> <a href='file:///Users/mattiacinelli/repositories/AlgoRL/.valgorl/lib/python3.8/site-packages/gym/core.py?line=253'>254</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/repositories/AlgoRL/.valgorl/lib/python3.8/site-packages/gym/envs/toy_text/frozen_lake.py:169\u001b[0m, in \u001b[0;36mFrozenLakeEnv.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/mattiacinelli/repositories/AlgoRL/.valgorl/lib/python3.8/site-packages/gym/envs/toy_text/frozen_lake.py?line=166'>167</a>\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/mattiacinelli/repositories/AlgoRL/.valgorl/lib/python3.8/site-packages/gym/envs/toy_text/frozen_lake.py?line=167'>168</a>\u001b[0m     \u001b[39mwith\u001b[39;00m closing(outfile):\n\u001b[0;32m--> <a href='file:///Users/mattiacinelli/repositories/AlgoRL/.valgorl/lib/python3.8/site-packages/gym/envs/toy_text/frozen_lake.py?line=168'>169</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m outfile\u001b[39m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py:299\u001b[0m, in \u001b[0;36mclosing.__exit__\u001b[0;34m(self, *exc_info)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py?line=297'>298</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mexc_info):\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py?line=298'>299</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mthing\u001b[39m.\u001b[39;49mclose()\n",
      "File \u001b[0;32m~/repositories/AlgoRL/.valgorl/lib/python3.8/site-packages/ipykernel/iostream.py:429\u001b[0m, in \u001b[0;36mOutStream.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/mattiacinelli/repositories/AlgoRL/.valgorl/lib/python3.8/site-packages/ipykernel/iostream.py?line=426'>427</a>\u001b[0m \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mplatform\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mlinux\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m sys\u001b[39m.\u001b[39mplatform\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mdarwin\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/mattiacinelli/repositories/AlgoRL/.valgorl/lib/python3.8/site-packages/ipykernel/iostream.py?line=427'>428</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_watch \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/mattiacinelli/repositories/AlgoRL/.valgorl/lib/python3.8/site-packages/ipykernel/iostream.py?line=428'>429</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwatch_fd_thread\u001b[39m.\u001b[39;49mjoin()\n\u001b[1;32m    <a href='file:///Users/mattiacinelli/repositories/AlgoRL/.valgorl/lib/python3.8/site-packages/ipykernel/iostream.py?line=429'>430</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc:\n\u001b[1;32m    <a href='file:///Users/mattiacinelli/repositories/AlgoRL/.valgorl/lib/python3.8/site-packages/ipykernel/iostream.py?line=430'>431</a>\u001b[0m     etype, value, tb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py:1011\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=1007'>1008</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=1009'>1010</a>\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=1010'>1011</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=1011'>1012</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=1012'>1013</a>\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=1013'>1014</a>\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=1014'>1015</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py:1027\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=1024'>1025</a>\u001b[0m \u001b[39mif\u001b[39;00m lock \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# already determined that the C code is done\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=1025'>1026</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_stopped\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=1026'>1027</a>\u001b[0m \u001b[39melif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=1027'>1028</a>\u001b[0m     lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=1028'>1029</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.render(mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  (Left)', 'SFFF', '\\x1b[41mF\\x1b[0mHFH', 'FFFH', 'HFFG', '']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = env.render(mode='ansi')\n",
    "type(a)\n",
    "a.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.action_space)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(MlpPolicy, env, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "You took an average of 37 steps to get the frisbee\n",
      "And you fell in the hole 28.00 % of the times\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def value_iteration(env, max_iterations=100000, lmbda=0.9):\n",
    "  stateValue = [0 for i in range(env.nS)]\n",
    "  newStateValue = stateValue.copy()\n",
    "  for i in range(max_iterations):\n",
    "    for state in range(env.nS):\n",
    "      action_values = []      \n",
    "      for action in range(env.nA):\n",
    "        state_value = 0\n",
    "        for i in range(len(env.P[state][action])):\n",
    "          prob, next_state, reward, done = env.P[state][action][i]\n",
    "          state_action_value = prob * (reward + lmbda*stateValue[next_state])\n",
    "          state_value += state_action_value\n",
    "        action_values.append(state_value)      #the value of each action\n",
    "        best_action = np.argmax(np.asarray(action_values))   # choose the action which gives the maximum value\n",
    "        newStateValue[state] = action_values[best_action]  #update the value of the state\n",
    "    if i > 1000: \n",
    "      if sum(stateValue) - sum(newStateValue) < 1e-04:   # if there is negligible difference break the loop\n",
    "        break\n",
    "        print(i)\n",
    "    else:\n",
    "      stateValue = newStateValue.copy()\n",
    "  return stateValue \n",
    "\n",
    "def get_policy(env,stateValue, lmbda=0.9):\n",
    "  policy = [0 for i in range(env.nS)]\n",
    "  for state in range(env.nS):\n",
    "    action_values = []\n",
    "    for action in range(env.nA):\n",
    "      action_value = 0\n",
    "      for i in range(len(env.P[state][action])):\n",
    "        prob, next_state, r, _ = env.P[state][action][i]\n",
    "        action_value += prob * (r + lmbda * stateValue[next_state])\n",
    "      action_values.append(action_value)\n",
    "    best_action = np.argmax(np.asarray(action_values))\n",
    "    policy[state] = best_action\n",
    "  return policy \n",
    "\n",
    "\n",
    "def get_score(env, policy, episodes=1000):\n",
    "  misses = 0\n",
    "  steps_list = []\n",
    "  for episode in range(episodes):\n",
    "    observation = env.reset()\n",
    "    steps=0\n",
    "    while True:\n",
    "      \n",
    "      action = policy[observation]\n",
    "      observation, reward, done, _ = env.step(action)\n",
    "      steps+=1\n",
    "      if done and reward == 1:\n",
    "        # print('You have got the fucking Frisbee after {} steps'.format(steps))\n",
    "        steps_list.append(steps)\n",
    "        break\n",
    "      elif done and reward == 0:\n",
    "        # print(\"You fell in a hole!\")\n",
    "        misses += 1\n",
    "        break\n",
    "  print('----------------------------------------------')\n",
    "  print('You took an average of {:.0f} steps to get the frisbee'.format(np.mean(steps_list)))\n",
    "  print('And you fell in the hole {:.2f} % of the times'.format((misses/episodes) * 100))\n",
    "  print('----------------------------------------------')\n",
    "\n",
    "\n",
    "\n",
    "env = gym.make('FrozenLake-v1')\n",
    "\n",
    "stateValues = value_iteration(env, max_iterations=100000)\n",
    "policy = get_policy(env, stateValues)\n",
    "get_score(env, policy,episodes=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "def show_videos(video_path='', prefix=''):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/eleurent/highway-env\n",
    "\n",
    "    :param video_path: (str) Path to the folder containing videos\n",
    "    :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
    "    \"\"\"\n",
    "    html = []\n",
    "    for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
    "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
    "        html.append('''<video alt=\"{}\" autoplay loop controls style=\"height: 400px;\">\n",
    "        <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
    "        </video>'''.format(mp4, video_b64.decode('ascii')))\n",
    "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
    "\n",
    "def record_video(env_id, model, video_length=500, prefix='', video_folder='videos/'):\n",
    "    \"\"\"\n",
    "    :param env_id: (str)\n",
    "    :param model: (RL model)\n",
    "    :param video_length: (int)\n",
    "    :param prefix: (str)\n",
    "    :param video_folder: (str)\n",
    "    \"\"\"\n",
    "    eval_env = DummyVecEnv([lambda: gym.make(env_id)])\n",
    "    # Start the video at step=0 and record 500 steps\n",
    "    eval_env = VecVideoRecorder(\n",
    "        eval_env, video_folder=video_folder,\n",
    "        record_video_trigger=lambda step: step == 0, video_length=video_length,\n",
    "        name_prefix=prefix)\n",
    "        \n",
    "    obs = eval_env.reset()\n",
    "    for _ in range(video_length):\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, _, _, _ = eval_env.step(action)\n",
    "\n",
    "  # Close the video recorder\n",
    "    eval_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_video(env_name, model, video_length=500, prefix='ppo2-'+env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_videos('videos', prefix='ppo2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "746acceb1a9bb722f8c89077fb130031d34e7e947823ee612a53301c7ebb3ca8"
  },
  "kernelspec": {
   "display_name": ".valgorl_nb",
   "language": "python",
   "name": ".valgorl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
