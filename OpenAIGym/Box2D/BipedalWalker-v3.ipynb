{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1694edaf-0c13-4f1a-a6f7-f4c0ce1a3d7f",
   "metadata": {},
   "source": [
    "# Setting up the `BipedalWalker-v3` environment\n",
    "\n",
    "The `gym` environment `BipedalWalker-v3` simulates a bipedal robot standing on an uneven surface. The goal is to teach the robot how to walk.\n",
    "\n",
    "![BipedalWalker-v3](bw.png)\n",
    "\n",
    "In the previous lesson, I showed you how to set up the `CartPole-v1` environment. Now, you are going to follow the same steps to set up the `BipedalWalker-v3` environment.\n",
    "\n",
    "Ready? Let's go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b28f1c-8a2b-4b60-91bb-1f27b75922ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# !pip install Box2D\n",
    "from stable_baselines3 import DQN, PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "456e44d5-9eeb-4352-9944-2b2942393662",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([-1. -1. -1. -1.], [1. 1. 1. 1.], (4,), float32)\n",
      "Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf], (24,), float32)\n"
     ]
    }
   ],
   "source": [
    "# Create the BipedalWalker-v3 environment and store it in a variable called env\n",
    "# Create folder to save models\n",
    "directory_path = 'models'\n",
    "Path(directory_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create environment\n",
    "env_name = 'BipedalWalker-v3'\n",
    "env = gym.make(env_name)\n",
    "\n",
    "num_steps = 5_0#00_000\n",
    "model_file_name = Path(directory_path, env_name + '_' + str(num_steps))\n",
    "print(env.action_space)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62796e77-aa14-4a1f-b065-e053576e5f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode n= 1, score= -83.79130894064167\n",
      "Episode n= 2, score= -101.9939853315934\n",
      "Episode n= 3, score= -108.91581433144042\n",
      "Episode n= 4, score= -113.7671551550962\n",
      "Episode n= 5, score= -106.72043106108593\n",
      "Episode n= 6, score= -108.14981128230225\n",
      "Episode n= 7, score= -79.92826934795367\n",
      "Episode n= 8, score= -79.0114705365611\n",
      "Episode n= 9, score= -116.3754665541115\n",
      "Mean reward:-99.85041250453179 Num episodes:10\n"
     ]
    }
   ],
   "source": [
    "# Reset the simulation to its initial state (this will start the simulation)\n",
    "def simulate_random_actions(render=False):\n",
    "    episodes = 10\n",
    "    all_rewards = []\n",
    "    for episode in range(1, episodes):\n",
    "        state = env.reset() # Restart the agent at the beginning\n",
    "        done = False # If the agent has completed the level\n",
    "        score = 0 # Called score not return cause it's python\n",
    "        while not done:\n",
    "            if render:\n",
    "                env.render()\n",
    "            random_action = env.action_space.sample() # Do random actions\n",
    "            _, reward, done, _ = env.step(random_action) \n",
    "            score += reward\n",
    "        all_rewards.append(score)\n",
    "        print(f'Episode n= {episode}, score= {score}')\n",
    "    env.reset()   \n",
    "    env.close()\n",
    "    print(f\"Mean reward:{np.mean(all_rewards)} Num episodes:{episodes}\")\n",
    "simulate_random_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38936bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO(policy = 'MlpPolicy', env = env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ac5221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7ff90b1155e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the agent\n",
    "model.learn(total_timesteps = num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0295297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "669195f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattiacinelli/repositories/AlgoRL/.valgorl/lib/python3.8/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward:-92.04 +/- 0.07\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model,  env , n_eval_episodes=10)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf023a2a-04d2-47a1-964f-aa32ce42e0d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-13 11:54:05.912 Python[46048:1446428] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to (null)\n"
     ]
    }
   ],
   "source": [
    "# Visualize the initial state\n",
    "env = gym.make(env_name)\n",
    "obs = env.reset()\n",
    "for _ in range(500):\n",
    "    env.render()\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "env.reset()   \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d558d7-715a-4340-83b6-65b01d3ae6cb",
   "metadata": {},
   "source": [
    "Do you see a pop-up window showing a bipedal robot standing on an grassy surface? If yes, then congratulations! You have successfully set up and started the `BipedalWalker-v3` environment. \n",
    "\n",
    "You can close the window by calling `env.close()`.\n",
    "\n",
    "If you are feeling brave, you can try setting up and visualizing other environments in the [Box2D](https://gym.openai.com/envs/#box2d) and [Classic Control](https://gym.openai.com/envs/#classic_control) sections."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
